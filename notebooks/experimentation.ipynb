{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694d1cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travisdawson/anaconda3/envs/Mimic-1/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import credentials\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import pinecone\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3006b9",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "This notebook serves as an experimentation on the components involved in the completion of the objective: Generate text in the author's style of writing, making use of stored document information and the knowledge of the trained LLM model. \n",
    "\n",
    "The variable breakdown of the experiment is as follows: \n",
    "\n",
    "### Constant Variables\n",
    "- Documents Uploaded (Documents contained are authored only by the intented mimic author)\n",
    "    - Character Growth Manifesto\n",
    "    - Tracking\n",
    "    - Form Follows Function\n",
    "    - Thriving Romantically\n",
    "- Queries Asked (Targeting a specific section of document generation)\n",
    "\n",
    "### Independent Variables\n",
    "- Embedding Chunk Size\n",
    "- Embedding Overlap\n",
    "- Query Search Method\n",
    "- Q&A LLM model\n",
    "- Q&A Cohesion Method\n",
    "- Generative Model Query\n",
    "\n",
    "### Dependent Variables\n",
    "- Generative output \\\n",
    "**Note:** Each output will have a stored set of variables describing the experimental parameters that produced that output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec12d08",
   "metadata": {},
   "source": [
    "## Simple Generative Case\n",
    "\n",
    "Create a simple example generative model ahead of creating experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e12b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"flourishing-humanity\"\n",
    "DIMENSION = 768\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 0\n",
    "EMBEDDINGS = HuggingFaceEmbeddings()\n",
    "QA_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0\n",
    "QUERY = \"What is the Character Growth manifesto?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8998f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials.set_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9e989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(os.getenv(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\"))\n",
    "\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(name=INDEX_NAME, dimension=DIMENSION)\n",
    "    \n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26b4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_path: str):\n",
    "    loader = DirectoryLoader(file_path, \n",
    "                             glob=\"**/*.txt\", \n",
    "                             loader_cls=TextLoader, \n",
    "                             show_progress=True)  # Directory uploader for txt documents\n",
    "    documents = loader.load()  # Load documents\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e7e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1645.63it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"../kb/\"\n",
    "documents = load_documents(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca358de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1089, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 2742, which is longer than the specified 1000\n",
      "Created a chunk of size 1144, which is longer than the specified 1000\n",
      "Created a chunk of size 1267, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1340, which is longer than the specified 1000\n",
      "Created a chunk of size 2111, which is longer than the specified 1000\n",
      "Created a chunk of size 1568, which is longer than the specified 1000\n",
      "Created a chunk of size 1930, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1295, which is longer than the specified 1000\n",
      "Created a chunk of size 1499, which is longer than the specified 1000\n",
      "Created a chunk of size 2921, which is longer than the specified 1000\n",
      "Created a chunk of size 1727, which is longer than the specified 1000\n",
      "Created a chunk of size 1433, which is longer than the specified 1000\n",
      "Created a chunk of size 1719, which is longer than the specified 1000\n",
      "Created a chunk of size 1270, which is longer than the specified 1000\n",
      "Created a chunk of size 1094, which is longer than the specified 1000\n",
      "Created a chunk of size 1839, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1051, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 1041, which is longer than the specified 1000\n",
      "Created a chunk of size 1201, which is longer than the specified 1000\n",
      "Created a chunk of size 1341, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1516, which is longer than the specified 1000\n",
      "Created a chunk of size 1907, which is longer than the specified 1000\n",
      "Created a chunk of size 1136, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1100, which is longer than the specified 1000\n",
      "Created a chunk of size 1002, which is longer than the specified 1000\n",
      "Created a chunk of size 1595, which is longer than the specified 1000\n",
      "Created a chunk of size 1183, which is longer than the specified 1000\n",
      "Created a chunk of size 1206, which is longer than the specified 1000\n",
      "Created a chunk of size 1480, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 1002, which is longer than the specified 1000\n",
      "Created a chunk of size 1789, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1437, which is longer than the specified 1000\n",
      "Created a chunk of size 2527, which is longer than the specified 1000\n",
      "Created a chunk of size 1280, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f53cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),  # find at app.pinecone.io\n",
    "    environment=os.getenv(\"PINECONE_ENV\"),  # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27653bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Pinecone.from_documents(docs, EMBEDDINGS, index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c27a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ea8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=QA_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8e1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ffc04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa({\"question\": QUERY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91e88f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Character Growth Manifesto is a comprehensive guide to personal growth and self-improvement. It provides actionable strategies and practical advice to help individuals build a stronger, more resilient character. The manifesto explores the foundations of character, the importance of character development, and offers a systematic approach to character growth. It encourages readers to identify promising character traits, select essential traits for growth, cultivate those traits with intention, and reflect on progress to continually evolve and grow. The goal of the manifesto is to empower individuals to reach their full potential and contribute to a more compassionate and harmonious society.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mimic-1",
   "language": "python",
   "name": "mimic-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
